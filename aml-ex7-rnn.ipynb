{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 582744 Advanced Course in Machine Learning\n",
    "\n",
    "## Exercise 7.1: Playing with RNNs\n",
    "\n",
    "This exercise contains most of the code needed in a Python jupyter notebook, you will be asked to fill in some important parts.  Just read the text and run each code cell by selecting and clicking the \"run cell\" button (play-like button), or by pressing shift-Enter.\n",
    "\n",
    "In this exercise we'll play a little bit with recurrent neural networks, in particular LSTMs.  We'll create a model that learns to predict the next character from a set of input characters. As training with a real dataset might be a bit too computationally expensive for an exercise, we'll just look at a toy example.\n",
    "\n",
    "Continue by running the cells below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll create our set of characters to use.  Let's use the lower case letters plus space. (You can edit this if you want to use more characters.)  We also create mapping dictionaries, so that we can easily map from the letter to the corresponding index, e.g., `char_to_int[\"a\"] = 0` and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz. \"\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll prepare some training data with a real sentence. The idea is to predict the next character from the previous one, so we'll make the input-output pairs of consecutive characters from the intput sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs:\n",
      "h -> e\n",
      "e -> l\n",
      "l -> l\n",
      "l -> o\n",
      "o ->  \n",
      "  -> w\n",
      "w -> o\n",
      "o -> r\n",
      "r -> l\n",
      "l -> d\n",
      "d ->  \n",
      "  -> t\n",
      "t -> h\n",
      "h -> i\n",
      "i -> s\n",
      "s ->  \n",
      "  -> i\n",
      "i -> s\n",
      "s ->  \n",
      "  -> j\n",
      "j -> u\n",
      "u -> s\n",
      "s -> t\n",
      "t ->  \n",
      "  -> a\n",
      "a ->  \n",
      "  -> t\n",
      "t -> e\n",
      "e -> s\n",
      "s -> t\n",
      "t ->  \n",
      "  -> s\n",
      "s -> e\n",
      "e -> n\n",
      "n -> t\n",
      "t -> e\n",
      "e -> n\n",
      "n -> c\n",
      "c -> e\n"
     ]
    }
   ],
   "source": [
    "# Here are some examples you can use ...\n",
    "\n",
    "# Learn the alphabet itself, i.e., predict the next letter (this one should be trivial)\n",
    "#data = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "# Learn a sentence (this should be a little bit harder)\n",
    "data = \"hello world this is just a test sentence\"\n",
    "\n",
    "# The \"The Adventures of Sherlock Holmes\" from Gutenberg.org, this will require hours of training to get \n",
    "# anything useful out... this will be a lot harder.  This is not required, but can be fun\n",
    "# if you have time.\n",
    "#r = urllib.request.urlopen(\"http://www.gutenberg.org/cache/epub/1661/pg1661.txt\")\n",
    "#raw_data = r.read().decode('utf8')\n",
    "#start_idx = raw_data.find(\"ADVENTURE I\")\n",
    "#end_idx = raw_data.find(\"End of the Project Gutenberg EBook\")\n",
    "#raw_data = raw_data[start_idx:end_idx]\n",
    "#data = [ch if ch in alphabet else \" \" for ch in raw_data.lower()]\n",
    "\n",
    "#print(\"Example of processed data:\", ''.join(data[:1000]))\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "verbose = True if len(data) < 50 else False\n",
    "\n",
    "if verbose:\n",
    "    print(\"Training pairs:\")\n",
    "    \n",
    "for i in range(len(data) - 1):\n",
    "    seq_in = data[i]\n",
    "    seq_out = data[i + 1]\n",
    "    dataX.append(char_to_int[seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "    if verbose:\n",
    "        print(seq_in, '->', seq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll reshape the training data so that `X` is a tensor with the format `(samples, time_steps, features)`. Here we are not using batches, so each item is a time step (`time_steps=1`) and the feature is just the character itself (`features=1`).\n",
    "\n",
    "The `y` is one-hot-encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 1, 1)\n",
      "(39, 28)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(dataX, (len(dataX), 1, 1))\n",
    "X = X / float(len(alphabet))\n",
    "\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Now, let's create an RNN model using LSTM.\n",
    "\n",
    "**Here is where you should add some code of your own!**\n",
    "\n",
    "Due to the way LSTM is implemented in Keras, it will normally reset its cell state after each batch. Here we want to train it in a way that remembers the internal state all the time, unless we explicitly reset it. To do this give the parameter `stateful=True` when you are adding the LSTM layer to the model. We can reset the state explicitly by calling `    model.reset_states()`. We are also not using batches, so each character is a batch of its own, so we use `batch_size=1`.\n",
    "\n",
    "For the first layer you should then give the parameter: `batch_input_shape=(batch_size, X.shape[1], X.shape[2])`.\n",
    "\n",
    "As always, the methods needed are described in [Keras' documentation](https://keras.io/).\n",
    "\n",
    "The output of the last layer needs to be a softmaxed vector to match the alphabet (size `y.shape[1]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_37 (LSTM)               (1, 1, 28)                3360      \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (1, 1, 84)                37968     \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (1, 1, 168)               170016    \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (1, 1, 84)                85008     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (1, 84)                   0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 28)                   2380      \n",
      "=================================================================\n",
      "Total params: 298,732\n",
      "Trainable params: 298,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model initialization:\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "\n",
    "# Example lines, change these to the correct ones!\n",
    "model.add(LSTM(y.shape[1], batch_input_shape=(batch_size, X.shape[1], X.shape[2]), return_sequences=True,stateful=True))\n",
    "model.add(LSTM(3*y.shape[1],activation='sigmoid',dropout=0.1,return_sequences=True,stateful=True))\n",
    "model.add(LSTM(6*y.shape[1],activation='tanh',dropout=0.1,return_sequences=True,stateful=True))\n",
    "model.add(LSTM(3*y.shape[1],activation='sigmoid',dropout=0.1,return_sequences=True,stateful=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "# Compile and print summary\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualise it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"553pt\" viewBox=\"0.00 0.00 287.00 553.00\" width=\"287pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-549 283,-549 283,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139884425971136 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139884425971136</title>\n",
       "<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 279,-544.5 279,-498.5 0,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-517.8\">lstm_37_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"163,-498.5 163,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"163,-521.5 218,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"218,-498.5 218,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-529.3\">(1, 1, 1)</text>\n",
       "<polyline fill=\"none\" points=\"218,-521.5 279,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-506.3\">(1, 1, 1)</text>\n",
       "</g>\n",
       "<!-- 139884425970688 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139884425970688</title>\n",
       "<polygon fill=\"none\" points=\"25.5,-415.5 25.5,-461.5 253.5,-461.5 253.5,-415.5 25.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-434.8\">lstm_37: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"130.5,-415.5 130.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"130.5,-438.5 185.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-415.5 185.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-446.3\">(1, 1, 1)</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-438.5 253.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-423.3\">(1, 1, 28)</text>\n",
       "</g>\n",
       "<!-- 139884425971136&#45;&gt;139884425970688 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139884425971136-&gt;139884425970688</title>\n",
       "<path d=\"M139.5,-498.366C139.5,-490.152 139.5,-480.658 139.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-471.607 139.5,-461.607 136,-471.607 143,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139884426260152 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139884426260152</title>\n",
       "<polygon fill=\"none\" points=\"25.5,-332.5 25.5,-378.5 253.5,-378.5 253.5,-332.5 25.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-351.8\">lstm_38: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"130.5,-332.5 130.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"130.5,-355.5 185.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-332.5 185.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-363.3\">(1, 1, 28)</text>\n",
       "<polyline fill=\"none\" points=\"185.5,-355.5 253.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-340.3\">(1, 1, 84)</text>\n",
       "</g>\n",
       "<!-- 139884425970688&#45;&gt;139884426260152 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139884425970688-&gt;139884426260152</title>\n",
       "<path d=\"M139.5,-415.366C139.5,-407.152 139.5,-397.658 139.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-388.607 139.5,-378.607 136,-388.607 143,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139884425971360 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139884425971360</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-249.5 22.5,-295.5 256.5,-295.5 256.5,-249.5 22.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75\" y=\"-268.8\">lstm_39: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-249.5 127.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-272.5 182.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-249.5 182.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-280.3\">(1, 1, 84)</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-272.5 256.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-257.3\">(1, 1, 168)</text>\n",
       "</g>\n",
       "<!-- 139884426260152&#45;&gt;139884425971360 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139884426260152-&gt;139884425971360</title>\n",
       "<path d=\"M139.5,-332.366C139.5,-324.152 139.5,-314.658 139.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-305.607 139.5,-295.607 136,-305.607 143,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139884416932216 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139884416932216</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-166.5 22.5,-212.5 256.5,-212.5 256.5,-166.5 22.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"75\" y=\"-185.8\">lstm_40: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-166.5 127.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-189.5 182.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-166.5 182.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-197.3\">(1, 1, 168)</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-189.5 256.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219.5\" y=\"-174.3\">(1, 1, 84)</text>\n",
       "</g>\n",
       "<!-- 139884425971360&#45;&gt;139884416932216 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139884425971360-&gt;139884416932216</title>\n",
       "<path d=\"M139.5,-249.366C139.5,-241.152 139.5,-231.658 139.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-222.607 139.5,-212.607 136,-222.607 143,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139884413685432 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139884413685432</title>\n",
       "<polygon fill=\"none\" points=\"20,-83.5 20,-129.5 259,-129.5 259,-83.5 20,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-102.8\">flatten_10: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"136,-83.5 136,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"136,-106.5 191,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191,-83.5 191,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-114.3\">(1, 1, 84)</text>\n",
       "<polyline fill=\"none\" points=\"191,-106.5 259,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-91.3\">(1, 84)</text>\n",
       "</g>\n",
       "<!-- 139884416932216&#45;&gt;139884413685432 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139884416932216-&gt;139884413685432</title>\n",
       "<path d=\"M139.5,-166.366C139.5,-158.152 139.5,-148.658 139.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-139.607 139.5,-129.607 136,-139.607 143,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139884411997264 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139884411997264</title>\n",
       "<polygon fill=\"none\" points=\"31,-0.5 31,-46.5 248,-46.5 248,-0.5 31,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-19.8\">dense_10: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140,-0.5 140,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-23.5 195,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"195,-0.5 195,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-31.3\">(1, 84)</text>\n",
       "<polyline fill=\"none\" points=\"195,-23.5 248,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-8.3\">(1, 28)</text>\n",
       "</g>\n",
       "<!-- 139884413685432&#45;&gt;139884411997264 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139884413685432-&gt;139884411997264</title>\n",
       "<path d=\"M139.5,-83.3664C139.5,-75.1516 139.5,-65.6579 139.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"143,-56.6068 139.5,-46.6068 136,-56.6069 143,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "Now let's train the LSTM model. As we have to reset the model manually, we'll run the `model.fit` function for one epoch, do the reset, and then run another in a loop.\n",
    "\n",
    "If you try with some bigger dataset, use `epocs=1` to start with... otherwise it will take forever. For example with the 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "39/39 [==============================] - 1s - loss: 3.2669 - acc: 0.1026     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.7403 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.6497 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.6168 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5901 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5604 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5651 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5711 - acc: 0.1282     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5765 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5664 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5530 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5001 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5470 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5951 - acc: 0.1282     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5292 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5201 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.4844 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5349 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.4951 - acc: 0.1282     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.5255 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.4420 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.4194 - acc: 0.2308     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.4124 - acc: 0.1026     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.3518 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.3931 - acc: 0.1026     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.2674 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.3500 - acc: 0.1538     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - ETA: 0s - loss: 2.1496 - acc: 0.250 - 0s - loss: 2.1778 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.2127 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.3287 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.3156 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.0861 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.0315 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.1401 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.0591 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.1198 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.1105 - acc: 0.2308     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.9525 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.9022 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8699 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8602 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.1077 - acc: 0.1795     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.0512 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.9137 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8729 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8795 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8142 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8425 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7904 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7521 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6956 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7255 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6770 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6502 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6059 - acc: 0.3590     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6923 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7294 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6395 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5870 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5737 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7045 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6532 - acc: 0.3590     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5020 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4683 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4789 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4359 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4842 - acc: 0.3846     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4198 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4280 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3842 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4292 - acc: 0.3590     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3803 - acc: 0.3846     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3624 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3382 - acc: 0.4872     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3604 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6752 - acc: 0.3846     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3881 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3208 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4630 - acc: 0.3590     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4719 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3702 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3266 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4098 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3383 - acc: 0.5641     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3500 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2835 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.0484 - acc: 0.2564     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8319 - acc: 0.2308     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8628 - acc: 0.2821     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 2.1713 - acc: 0.2308     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4720 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4585 - acc: 0.4615     \n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s - loss: 1.3673 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3168 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2591 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2490 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4621 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2599 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4292 - acc: 0.3846     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3422 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5590 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4340 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2451 - acc: 0.4872     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.2618 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1066 - acc: 0.5641     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0481 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1224 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1726 - acc: 0.5641     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0206 - acc: 0.5897     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9841 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9669 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9514 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0190 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0248 - acc: 0.5897     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1667 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5964 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0062 - acc: 0.5897     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.5601 - acc: 0.3333     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0936 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3078 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9852 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0446 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8971 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9138 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8770 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8155 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8106 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8053 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7858 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7581 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7575 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7159 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6995 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7805 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8046 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7461 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7162 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7502 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6579 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9012 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3788 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4925 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8928 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0170 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9635 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8691 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7536 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7232 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7104 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6871 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6574 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6122 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6430 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6296 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6636 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5914 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7042 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6401 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5855 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1179 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6244 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6367 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6943 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6074 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6200 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5749 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6796 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5464 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5618 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5095 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5975 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5795 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4920 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5038 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4526 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4379 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4161 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4153 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3824 - acc: 1.0000     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3786 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3917 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3769 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3719 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4363 - acc: 0.8462     \n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.4536 - acc: 0.727 - 0s - loss: 0.5431 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5830 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3709 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3524 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3806 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4506 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3632 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3227 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2928 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2621 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2679 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2742 - acc: 1.0000     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2837 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3024 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8287 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5341 - acc: 0.6923     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5046 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5853 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7546 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5322 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8180 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6129 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4631 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3604 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2921 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2841 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3068 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5017 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3583 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2851 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2439 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2451 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3234 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4459 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3761 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3620 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2371 - acc: 1.0000     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2787 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3070 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2305 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3287 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0508 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4440 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7569 - acc: 0.6410     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.6992 - acc: 0.3590     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.4655 - acc: 0.5128     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 4.7813 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 3.3274 - acc: 0.2051     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.7909 - acc: 0.4103     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.3527 - acc: 0.4359     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1751 - acc: 0.5385     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9571 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8150 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7395 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7049 - acc: 0.7436     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6476 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7100 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.1275 - acc: 0.4615     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9374 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.8041 - acc: 0.3077     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 1.0022 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.8099 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7086 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6526 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6630 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6805 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5612 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5408 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6654 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6323 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5589 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5147 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4433 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4495 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4869 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5472 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4674 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5081 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5294 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6862 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6227 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4727 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4552 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3958 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3303 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3409 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6899 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4300 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3869 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3268 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2945 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3135 - acc: 0.9231     \n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s - loss: 0.5694 - acc: 0.7179     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4352 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3332 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2536 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2443 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3680 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.7992 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6188 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4072 - acc: 0.8462     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4523 - acc: 0.8205     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5765 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.6831 - acc: 0.6154     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.9667 - acc: 0.4872     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.5861 - acc: 0.6667     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.4284 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3309 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3871 - acc: 0.7949     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3977 - acc: 0.7692     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2903 - acc: 0.8974     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2898 - acc: 0.9744     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2799 - acc: 0.9487     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3115 - acc: 0.9231     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.3061 - acc: 0.8718     \n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s - loss: 0.2437 - acc: 0.9231     \n",
      "CPU times: user 3min 54s, sys: 18.4 s, total: 4min 12s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "epocs=300\n",
    "\n",
    "for i in range(epocs):\n",
    "    model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "    model.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see the final accuracy of the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 94.87%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "model.reset_states()\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test outputs\n",
    "\n",
    "Now, let's see some outputs. We'll start by making a function that predicts the next `n` chars given a starting character `start_char`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_next_chars(start_chars, n, verbose=False):\n",
    "    all_chars = start_chars\n",
    "    for i in range(n):\n",
    "        x = np.reshape(char_to_int[start_chars[0]], (1, 1, 1))\n",
    "        x = x / float(len(alphabet))\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        \n",
    "        # if we were given more than one start char, continue feeding those\n",
    "        if len(start_chars) > 1:\n",
    "            start_chars = start_chars[1:]\n",
    "        else: # otherwise, we predict the next character\n",
    "            next_char = int_to_char[np.argmax(prediction)]\n",
    "            if verbose:\n",
    "                print(start_chars, \"->\", next_char)\n",
    "            all_chars += next_char\n",
    "            start_chars = next_char\n",
    "    model.reset_states()\n",
    "    print(\"\\nThe full predicted text string:\", all_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try inputting the first letter of our training data.  Giving `True` as the third parameter to the function causes it to print each prediction as it happens.  Set it to `False` if you want less verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h -> e\n",
      "e -> l\n",
      "l -> l\n",
      "l -> o\n",
      "o ->  \n",
      "  -> w\n",
      "w -> o\n",
      "o -> r\n",
      "r -> l\n",
      "l -> d\n",
      "d ->  \n",
      "  -> t\n",
      "t -> h\n",
      "h -> i\n",
      "i -> s\n",
      "s ->  \n",
      "  -> i\n",
      "i -> s\n",
      "s ->  \n",
      "  -> j\n",
      "j -> u\n",
      "u -> s\n",
      "s -> t\n",
      "t ->  \n",
      "  -> a\n",
      "a ->  \n",
      "  -> t\n",
      "t -> e\n",
      "e -> s\n",
      "s -> t\n",
      "\n",
      "The full predicted text string: hello world this is just a test\n"
     ]
    }
   ],
   "source": [
    "predict_next_chars(data[0], 30, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output will probably not be perfect, but you should see that it has learned something.  You can try with different starting letters, and experiment with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The full predicted text string: abxlo world this is just a test sentcececececececececececececececececelelellllllllololollloltltltldld\n"
     ]
    }
   ],
   "source": [
    "predict_next_chars('abx', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
